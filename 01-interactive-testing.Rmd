---
title: "Interative Experiments"
author: "Lukas"
date: "`r Sys.Date()`"
output: 
  html_document: 
    fig_caption: yes
    self_contained: no
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Load helper functions in R/
source(here::here("R/sim_cr.R"))
source(here::here("R/mt_res_tidy_plot.R"))

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  out.width = "100%"
)

library(fwelnet)
library(ggplot2)
```

Before we set up a proper benchmarking experiment, this serves as a platform for quick-and-dirty interactive experimentation.

## Simulate data

Generate predictors:

```{r sim-data-x}
n <- 1000
# create data set with covariates
df <- tibble::tibble(
  x0 = sample(c(-1,1), n, .3),
  x1 = runif(n, -3, 3),
  x2 = runif(n, -3, 3),
  x3 = runif(n, -3, 3))
df2 <- mvtnorm::rmvnorm(n = nrow(df), mean = rep(0, 10))
# noise variables
colnames(df2) <- paste0("x", 4:(ncol(df2)+3))
df <- cbind(df, df2)
```

Generate CR endpoint via formula specification and note true effects in separate tbl for plotting purposes (a cleaner solution would be preferable):

```{r sim-data-y}
set.seed(997)
sim1 <- sim_wrapper_cr(
  formula = 
    ~ -1 + 2*dgamma(t, 8, 2) + 1 * x1 + 0.5 * x2 | 
      -1 + 2*dgamma(t, 8, 2) + 1 * x1 + 0.5 * x2,
  data = df
)

table(sim1$status)

true_effects <- tibble::tribble(
  ~beta,    ~x,  ~truth,
  "beta1", "x1", 1,
  "beta1", "x2", 0.5,
  "beta2", "x1", 1,
  "beta2", "x2", 0.5
)
```

## Run algorithm

Run and plot result individually:

```{r run-plot, eval=FALSE}
set.seed(997)
fwelnet_mt_cox(
  sim1, mt_max_iter = 5,
  z_scale = 1, z_method = "original"
) |>
  tidy_mt_res(true_effects) |>
  plot_mt_res(true_effects)

set.seed(997)
fwelnet_mt_cox(
  sim1, mt_max_iter = 5,
  z_scale = 100, z_method = "original"
) |>
  tidy_mt_res(true_effects) |>
  plot_mt_res(true_effects)
```

Or maybe something like this, to plot multiple settings side by side?

```{r run-plot-all, fig.height = 8, fig.width = 13}
set.seed(997)
res1 <- fwelnet_mt_cox(sim1, mt_max_iter = 2, z_scale = 1, z_method = "original") 
set.seed(997)
res2 <- fwelnet_mt_cox(sim1, mt_max_iter = 2, z_scale = 100, z_method = "original") 
set.seed(997)
res3 <- fwelnet_mt_cox(sim1, mt_max_iter = 2, z_scale = 1, z_method = "aligned") 
set.seed(997)
res4 <- fwelnet_mt_cox(sim1, mt_max_iter = 2, z_scale = 100, z_method = "aligned") 

res_full <- purrr::map_df(list(res1, res2, res3, res4), ~tidy_mt_res(.x, true_effects))

ggplot(res_full, aes(x = iter, y = value, color = xcol, alpha = is_noise)) +
  facet_grid(
    cols = vars(z_method, z_scale), rows = vars(beta),
    labeller = label_context
  ) +
  geom_hline(data = true_effects, aes(yintercept = truth), lty = "dotted") +
  geom_path() +
  scale_x_continuous(breaks = seq(0, 100, 1)) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(
    values = c("True effect" = 1, "Noise" = 0.2),
    guide = "none"
  ) +
  labs(
    title = "Multi-Task fwelnet: Multiple results",
    x = "# of Multi-Task Iterations",
    y = "Effect estimate",
    color = "Variable"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.y = unit(1, "cm"),
    legend.position = "top", 
    plot.title.position = "plot"
  )

```

Comparing `z_method` and `z_scale`:

```{r tab-comparison}
# res_full |>
#   dplyr::filter(is_noise != "Noise", z_scale == 1) |>
#   dplyr::select(-is_noise, -xcol, -z_scale, -converged) |> 
#   tidyr::pivot_wider(id_cols = c("x", "iter", "beta"), names_from = "z_method", values_from = "value")

res_full |>
  dplyr::filter(is_noise != "Noise") |>
  dplyr::select(-is_noise, -xcol, -converged) |> 
  tidyr::pivot_wider(id_cols = c("x", "iter", "beta"), names_from = c("z_method", "z_scale"), values_from = "value") |>
  dplyr::select(beta, dplyr::everything()) |>
  dplyr::left_join(true_effects, by = c("beta", "x")) |>
  knitr::kable(
    caption = "Comparison of z_method = {original, aligned} and z_scale = {1, 100}"
  ) |>
  kableExtra::kable_styling() |>
  kableExtra::collapse_rows(columns = c(1, 2))
```

